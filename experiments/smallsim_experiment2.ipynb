{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "I find an improved implementation of anchor-word algorithm at https://aclanthology.org/D19-1504.pdf . I want to see how well it performs on a simulated dataset that satsifies the \"anchor-word\" assumption. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "script_dir = \"../\"\n",
    "sys.path.append(os.path.abspath(script_dir))\n",
    "from file2 import *\n",
    "from factorize import *\n",
    "from smallsim_functions_anchor import *\n",
    "from misc import *\n",
    "\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## small, uncorrelated example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[file.bows2C] Start constructing dense C...\n",
      "- Counting the co-occurrence for each document...\n",
      "+ Finish constructing C and D!\n",
      "  - The sum of all entries = 1.000000\n",
      "  - Elapsed Time = 0.6452 seconds\n"
     ]
    }
   ],
   "source": [
    "n = 1000\n",
    "p = 400\n",
    "k = 4\n",
    "doc_len = 1000\n",
    "\n",
    "sim = smallsim_independent(n = n, p = p, k = k, doc_len = doc_len)\n",
    "X = sparse.coo_matrix(sim[\"X\"])\n",
    "L = sim[\"L\"]\n",
    "F = sim[\"F\"]\n",
    "anchor_words = sim[\"anchor_words\"]\n",
    "id_m = sim[\"id_m\"]\n",
    "\n",
    "Bows = X2Bows(X)\n",
    "C, D1, D2 = bows2C(Bows, min_tokens=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ Start rectifying C...\n",
      "+ Start alternating projection\n",
      "  - 1-th iteration... (3.040130e-05 / 4.621196e-10)\n",
      "  - 2-th iteration... (1.491654e-08 / 4.621200e-10)\n",
      "  - 3-th iteration... (9.905184e-09 / 4.621204e-10)\n",
      "  - 4-th iteration... (6.577451e-09 / 4.621207e-10)\n",
      "  - 5-th iteration... (4.367703e-09 / 4.621209e-10)\n",
      "  - 6-th iteration... (2.900339e-09 / 4.621211e-10)\n",
      "  - 7-th iteration... (1.925949e-09 / 4.621212e-10)\n",
      "  - 8-th iteration... (1.278912e-09 / 4.621213e-10)\n",
      "  - 9-th iteration... (8.492528e-10 / 4.621213e-10)\n",
      "  - 10-th iteration... (5.639404e-10 / 4.621214e-10)\n",
      "  - 11-th iteration... (3.744807e-10 / 4.621214e-10)\n",
      "  - 12-th iteration... (2.486713e-10 / 4.621214e-10)\n",
      "  - 13-th iteration... (1.651285e-10 / 4.621214e-10)\n",
      "  - 14-th iteration... (1.096524e-10 / 4.621214e-10)\n",
      "  - 15-th iteration... (7.281394e-11 / 4.621214e-10)\n",
      "+ Finish alternating projection\n",
      "  - Elapsed seconds = 0.0690\n",
      "\n",
      "  - Finish rectifying C! [0.069019]\n",
      "+ Start finding the set of anchor bases S...\n",
      "[inference.findS] Start finding the set of anchor bases S...\n",
      "+ Finish finding set S!\n",
      "  - Discovered 4 basis vectors by [sparsePartial] method.\n",
      "  - Elapsed time = 0.0015 seconds\n",
      "\n",
      "  - Finish finding S! [0.001494]\n",
      "+ Start recovering the object-cluster B...\n",
      "[inference.recoverB] Start recovering the object-cluster B...\n",
      "  - 0-th member...\n",
      "+ Finish recovering B matrix using [activeSet]\n",
      "  - 4/400 objects are converged.\n",
      "  - loss = 3.1819 (By Frobenius norm).\n",
      "  - Elapsed time = 0.4458 seconds.\n",
      "\n",
      "  - Finish recovering B! [0.445830]\n",
      "+ Start recovering the cluster-cluster A...\n",
      "[inference.recoverA] Start recovering the cluster-cluster A...\n",
      "+ Finish recovering A!\n",
      "  - [diagonal] recovery is used.\n",
      "  - Elapsed time = 0.0003 seconds.\n",
      "\n",
      "  - Finish recovering A! [0.000275]\n",
      "- Finish factorizing C! [0.519169]\n"
     ]
    }
   ],
   "source": [
    "S, B, A, Btilde, Cbar, C_rowSums, diagR, C = factorizeC(C, K=k, rectifier='AP', optimizer='activeSet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaulate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 3, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_idx = match_topics(F, B).astype(int)\n",
    "topic_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 85,  85],\n",
       "       [367, 367],\n",
       "       [110, 110],\n",
       "       [319, 319]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.column_stack((S[topic_idx], anchor_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True, True]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cand_set = set(np.unique(id_m))\n",
    "[w in cand_set for w in S]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07, 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.08, 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.07, 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.08]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F[anchor_words,:].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.069, 0.   , 0.   , 0.   ],\n",
       "       [0.   , 0.077, 0.   , 0.   ],\n",
       "       [0.   , 0.   , 0.08 , 0.   ],\n",
       "       [0.   , 0.   , 0.   , 0.072]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B[anchor_words[topic_idx],:].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2 , 0.02, 0.02, 0.02],\n",
       "       [0.02, 0.18, 0.02, 0.02],\n",
       "       [0.02, 0.02, 0.17, 0.02],\n",
       "       [0.02, 0.02, 0.02, 0.19]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare A and LLt/n\n",
    "A_reorder = A[topic_idx,:]\n",
    "A_reorder = A_reorder[:, topic_idx]\n",
    "A_reorder.round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2 , 0.02, 0.02, 0.02],\n",
       "       [0.02, 0.17, 0.02, 0.02],\n",
       "       [0.02, 0.02, 0.17, 0.02],\n",
       "       [0.02, 0.02, 0.02, 0.2 ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = sim[\"L\"]\n",
    "(L.T.dot(L)/n).round(decimals=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA can find those anchor words very well too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lda = LatentDirichletAllocation(n_components=k, max_iter=20,\n",
    "#                                 random_state=0)\n",
    "# lda.fit(X)\n",
    "\n",
    "# B2 = (lda.components_ / lda.components_.sum(axis=1)[:, np.newaxis]).T\n",
    "# idx = match_topics(B2, F).astype(int)\n",
    "# B2[anchor_words[idx],:].round(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
