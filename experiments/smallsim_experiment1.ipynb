{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "I find an improved implementation of anchor-word algorithm at https://aclanthology.org/D19-1504.pdf . I want to see how well it performs on a simulated dataset that slightly violates the \"anchor-word\" assumption. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "script_dir = \"../\"\n",
    "sys.path.append(os.path.abspath(script_dir))\n",
    "from file2 import *\n",
    "from factorize import *\n",
    "from smallsim_functions import *\n",
    "from misc import *\n",
    "\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## small, uncorrelated example\n",
    "\n",
    "I simulate a count matrix from $L, F$, with each column of $F$ has 20 words that is 100 times more expressed than the rest words. This will not satisfy the strict \"anchor word\" assumption, but it's close: $F_{s_k, k} >> F_{s_k, l}, \\forall l \\neq k$ where $s_k$ is \"approximate\" anchor word for topic $k$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[file.bows2C] Start constructing dense C...\n",
      "- Counting the co-occurrence for each document...\n",
      "+ Finish constructing C and D!\n",
      "  - The sum of all entries = 1.000000\n",
      "  - Elapsed Time = 0.0530 seconds\n"
     ]
    }
   ],
   "source": [
    "n = 600\n",
    "p = 400\n",
    "k = 6\n",
    "doc_len = 50\n",
    "\n",
    "sim = smallsim_independent(n = n, p = p, k = k, doc_len = doc_len)\n",
    "X = sparse.coo_matrix(sim[\"X\"])\n",
    "L = sim[\"L\"]\n",
    "F = sim[\"F\"]\n",
    "id_m = sim[\"id_m\"]\n",
    "C, D1, D2 = X2C(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ Start rectifying C...\n",
      "+ Start alternating projection\n",
      "  - 1-th iteration... (7.469974e-04 / 2.790099e-07)\n",
      "  - 2-th iteration... (1.510219e-06 / 2.790142e-07)\n",
      "  - 3-th iteration... (9.042341e-07 / 2.790178e-07)\n",
      "  - 4-th iteration... (6.287480e-07 / 2.790207e-07)\n",
      "  - 5-th iteration... (4.865718e-07 / 2.790230e-07)\n",
      "  - 6-th iteration... (3.969262e-07 / 2.790250e-07)\n",
      "  - 7-th iteration... (3.346263e-07 / 2.790267e-07)\n",
      "  - 8-th iteration... (2.876316e-07 / 2.790282e-07)\n",
      "  - 9-th iteration... (2.504964e-07 / 2.790295e-07)\n",
      "  - 10-th iteration... (2.201664e-07 / 2.790307e-07)\n",
      "  - 11-th iteration... (1.947226e-07 / 2.790318e-07)\n",
      "  - 12-th iteration... (1.736961e-07 / 2.790328e-07)\n",
      "  - 13-th iteration... (1.564211e-07 / 2.790337e-07)\n",
      "  - 14-th iteration... (1.413543e-07 / 2.790345e-07)\n",
      "  - 15-th iteration... (1.281040e-07 / 2.790352e-07)\n",
      "+ Finish alternating projection\n",
      "  - Elapsed seconds = 0.1108\n",
      "\n",
      "  - Finish rectifying C! [0.110793]\n",
      "+ Start finding the set of anchor bases S...\n",
      "[inference.findS] Start finding the set of anchor bases S...\n",
      "+ Finish finding set S!\n",
      "  - Discovered 6 basis vectors by [sparsePartial] method.\n",
      "  - Elapsed time = 0.0018 seconds\n",
      "\n",
      "  - Finish finding S! [0.001838]\n",
      "+ Start recovering the object-cluster B...\n",
      "[inference.recoverB] Start recovering the object-cluster B...\n",
      "  - 0-th member...\n",
      "+ Finish recovering B matrix using [activeSet]\n",
      "  - 6/400 objects are converged.\n",
      "  - loss = 2.9185 (By Frobenius norm).\n",
      "  - Elapsed time = 0.6578 seconds.\n",
      "\n",
      "  - Finish recovering B! [0.657833]\n",
      "+ Start recovering the cluster-cluster A...\n",
      "[inference.recoverA] Start recovering the cluster-cluster A...\n",
      "+ Finish recovering A!\n",
      "  - [diagonal] recovery is used.\n",
      "  - Elapsed time = 0.0003 seconds.\n",
      "\n",
      "  - Finish recovering A! [0.000281]\n",
      "- Finish factorizing C! [0.773376]\n"
     ]
    }
   ],
   "source": [
    "S, B, A, Btilde, Cbar, C_rowSums, diagR, C = factorizeC(C, K=k, rectifier='AP', optimizer='activeSet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaulate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 5, 3, 2, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_idx = match_topics(F, B).astype(int)\n",
    "topic_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True, True, False, True]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cand_set = set(np.unique(id_m))\n",
    "[w in cand_set for w in S]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.   , 0.   , 0.   , 0.001],\n",
       "       [0.001, 0.062, 0.001, 0.   , 0.   , 0.   ],\n",
       "       [0.001, 0.   , 0.038, 0.   , 0.001, 0.001],\n",
       "       [0.001, 0.   , 0.   , 0.059, 0.   , 0.   ],\n",
       "       [0.   , 0.   , 0.   , 0.   , 0.029, 0.   ],\n",
       "       [0.001, 0.   , 0.   , 0.001, 0.   , 0.076]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F[S[topic_idx],:].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11, 0.01, 0.  , 0.  , 0.01, 0.02],\n",
       "       [0.01, 0.15, 0.01, 0.01, 0.01, 0.01],\n",
       "       [0.  , 0.01, 0.13, 0.02, 0.01, 0.01],\n",
       "       [0.  , 0.01, 0.02, 0.12, 0.01, 0.01],\n",
       "       [0.01, 0.01, 0.01, 0.01, 0.09, 0.01],\n",
       "       [0.02, 0.01, 0.01, 0.01, 0.01, 0.12]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare A and LLt/n\n",
    "A_reorder = A[topic_idx,:]\n",
    "A_reorder = A_reorder[:, topic_idx]\n",
    "A_reorder.round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1 , 0.01, 0.01, 0.01, 0.01, 0.01],\n",
       "       [0.01, 0.13, 0.01, 0.01, 0.01, 0.01],\n",
       "       [0.01, 0.01, 0.11, 0.01, 0.01, 0.01],\n",
       "       [0.01, 0.01, 0.01, 0.11, 0.01, 0.01],\n",
       "       [0.01, 0.01, 0.01, 0.01, 0.09, 0.01],\n",
       "       [0.01, 0.01, 0.01, 0.01, 0.01, 0.12]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = sim[\"L\"]\n",
    "(L.T.dot(L)/n).round(decimals=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
